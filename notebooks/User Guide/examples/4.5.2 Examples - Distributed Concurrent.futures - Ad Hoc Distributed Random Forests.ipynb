{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples - Distributed Concurrent.futures \n",
    "## - Ad Hoc Distributed Random Forests\n",
    "https://gist.github.com/mrocklin/9f5720d8658e5f2f66666815b1f03f00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ad-Hoc Distributed Random Forests on NYCTaxi Dataframes\n",
    "=======================================================\n",
    "\n",
    "Using Dask.distributed and Scikit-Learn we train a distributed random forest on the NYCTaxi data.\n",
    "\n",
    "**Learning Objective**: Predict passenger counts given fare, distance, location, etc..\n",
    "\n",
    "**Actual Objective**: Show how to use dask.distributed in a free-form way without collections\n",
    "\n",
    "**Disclaimer**: Our machine learning approach is flawed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:52993\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>8.48 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:52993' processes=4 cores=4>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from distributed import Client, progress, wait\n",
    "e = Client()\n",
    "e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NYCTaxi data living on S3\n",
    "\n",
    "This is something like 60GB in RAM.\n",
    "\n",
    "We'll try to predict `passenger_count` given the other numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dask-data/nyc-taxi/2015/yellow_tripdata_2015-01.csv',\n",
       " 'dask-data/nyc-taxi/2015/yellow_tripdata_2015-02.csv',\n",
       " 'dask-data/nyc-taxi/2015/yellow_tripdata_2015-03.csv',\n",
       " 'dask-data/nyc-taxi/2015/yellow_tripdata_2015-04.csv',\n",
       " 'dask-data/nyc-taxi/2015/yellow_tripdata_2015-05.csv',\n",
       " 'dask-data/nyc-taxi/2015/yellow_tripdata_2015-06.csv',\n",
       " 'dask-data/nyc-taxi/2015/yellow_tripdata_2015-07.csv',\n",
       " 'dask-data/nyc-taxi/2015/yellow_tripdata_2015-08.csv',\n",
       " 'dask-data/nyc-taxi/2015/yellow_tripdata_2015-09.csv',\n",
       " 'dask-data/nyc-taxi/2015/yellow_tripdata_2015-10.csv',\n",
       " 'dask-data/nyc-taxi/2015/yellow_tripdata_2015-11.csv',\n",
       " 'dask-data/nyc-taxi/2015/yellow_tripdata_2015-12.csv',\n",
       " 'dask-data/nyc-taxi/2015/parquet.gz',\n",
       " 'dask-data/nyc-taxi/2015/parquet',\n",
       " 'dask-data/nyc-taxi/2015/yellow_tripdata_2015-01.parq']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from s3fs import S3FileSystem\n",
    "\n",
    "s3 = S3FileSystem(anon=True)\n",
    "s3.ls('dask-data/nyc-taxi/2015/', detail = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "dfs = dd.read_csv('s3://dask-data/nyc-taxi/2015/*.csv', \n",
    "                  parse_dates=['tpep_pickup_datetime', \n",
    "                               'tpep_dropoff_datetime'],\n",
    "                  collection=False,\n",
    "                  storage_options={'anon': True})\n",
    "\n",
    "dfs = e.compute(dfs)\n",
    "# dfs\n",
    "# progress(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Future: status: pending, key: pandas_read_text-652ad00ebcf26f069e83ac511ca8e5b0>,\n",
       " <Future: status: pending, key: pandas_read_text-da3e150dfdbb37450dab2e148a1c79b8>,\n",
       " <Future: status: pending, key: pandas_read_text-bc5a23b8662841cbf0f2aa0c97d4575f>,\n",
       " <Future: status: pending, key: pandas_read_text-e423eb879458e1baede77b52c66d3956>,\n",
       " <Future: status: pending, key: pandas_read_text-0f9a3ec9ba3f351aede693f98e1840ee>,\n",
       " <Future: status: pending, key: pandas_read_text-6b611c79ca55007bddd5cbfae9222e96>,\n",
       " <Future: status: pending, key: pandas_read_text-347e6ddcbd530efe148644b23601baa3>,\n",
       " <Future: status: pending, key: pandas_read_text-fc5e73db2ad00009ccee0b7c48e1351a>,\n",
       " <Future: status: pending, key: pandas_read_text-ac2d6159ca15202e08d06a7d3a6bd55a>,\n",
       " <Future: status: pending, key: pandas_read_text-dd52425f74171b3b0318a8796cf15275>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Future: pandas_read_text</b> <font color=\"gray\">status: </font><font color=\"black\">pending</font>, <font color=\"gray\">key: </font>pandas_read_text-652ad00ebcf26f069e83ac511ca8e5b0"
      ],
      "text/plain": [
       "<Future: status: pending, key: pandas_read_text-652ad00ebcf26f069e83ac511ca8e5b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfs[0].result()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start with a sample on a single machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "columns = ['trip_distance', 'pickup_longitude', 'pickup_latitude', \n",
    "           'dropoff_longitude', 'dropoff_latitude', 'payment_type', \n",
    "           'fare_amount', 'mta_tax', 'tip_amount', 'tolls_amount']\n",
    "\n",
    "est = RandomForestClassifier(n_estimators=4)\n",
    "est.fit(df_train[columns], df_train.passenger_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est.score(df_test[columns], df_test.passenger_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, 65% accuracy isn't bad.  \n",
    "\n",
    "But really, always guessing a single passenger wouldn't be that much worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "accuracy_score(df_test.passenger_count, \n",
    "               np.ones_like(df_test.passenger_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_test.passenger_count == 1).sum() / len(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So lets just be upfront that I'm probably not choosing the correct algorithms here.  Machine learning requires at least a little bit of expertise to do well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed fit with `e.map`\n",
    "\n",
    "Lets keep going through the motions of fitting on a cluster though.  It'll be informative, I promise.\n",
    "\n",
    "We'll map a function across our futures with `e.map`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(df):\n",
    "    est = RandomForestClassifier(n_estimators=4)\n",
    "    est.fit(df[columns], df.passenger_count)\n",
    "    return est\n",
    "\n",
    "train = dfs[:-1]\n",
    "test = dfs[-1]\n",
    "\n",
    "estimators = e.map(fit, train)\n",
    "progress(estimators, complete=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcast our test data across all nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time e.replicate([test], n=48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions from each of our models\n",
    "\n",
    "We'll use `e.submit(function, *args)` in a loop to submit more tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(est, X):\n",
    "    return est.predict(X[columns])\n",
    "\n",
    "predictions = [e.submit(predict, est, test) for est in estimators]\n",
    "progress(predictions, complete=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = predictions[3].result()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate by Majority Vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "import numpy as np\n",
    "\n",
    "def mymode(*arrays):\n",
    "    array = np.stack(arrays, axis=0)\n",
    "    return mode(array)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_few_predictions = e.gather(predictions[:4])\n",
    "a_few_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymode(*a_few_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree reduce predictions together to single prediciton\n",
    "\n",
    "We'll use `e.submit(...)` in a nested loop for more interesting tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolz import partition_all\n",
    "preds = predictions\n",
    "while len(preds) > 1:\n",
    "    preds = [e.submit(mymode, *chunk) \n",
    "             for chunk in partition_all(10, preds)]\n",
    "progress(preds, complete=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = e.gather(preds)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(result, test.result().passenger_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Too many single-passenger rides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolz import frequencies\n",
    "frequencies(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies(predictions[3].result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "*  Saw dask.distributed task API\n",
    "    * `e.submit(function, *args)`\n",
    "    * `e.map(function, sequence)`\n",
    "    * `e.gather(futures)`\n",
    "\n",
    "*  Our machine learning algorithms could improve\n",
    "*  Replicate with [dec2](https://github.com/dask/dec2/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
